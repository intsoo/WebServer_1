{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1-1(final).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intsoo/WebServer_1/blob/main/HW1_1(final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2022-1 Artificial Intelligence (01)\n",
        "## Homework #1: MLP from the scratch\n",
        "---\n",
        "Copyright (c) Prof. Jaehyeong Sim \n",
        "\n",
        "Department of Computer Science and Engineering\n",
        "\n",
        "Ewha Womans University"
      ],
      "metadata": {
        "id": "JJeY52mkwqe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "LOgtScJ6VfFi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid function\n",
        "def sigmoid(x):\n",
        "  # Problem 1.(a): fill here\n",
        "  result = 1.0 / (1.0 + np.exp((-1)*x))\n",
        "  return result\n",
        "\n",
        "# Derivative of sigmoid function\n",
        "def dsigmoid(x):\n",
        "  # Problem 1.(a): fill here\n",
        "  sigmoidX = sigmoid(x)\n",
        "  result = sigmoidX * (1 - sigmoidX)\n",
        "  return result\n",
        "\n",
        "# Hyperbolic tangent function\n",
        "def tanh(x):\n",
        "  # Problem 1.(a): fill here\n",
        "  result = np.tanh(x)\n",
        "  return result\n",
        "\n",
        "# Derivative of hyperbolic tangent function\n",
        "def dtanh(x):\n",
        "  # Problem 1.(a): fill here\n",
        "  result = 1 - tanh(x) ** 2\n",
        "  return result"
      ],
      "metadata": {
        "id": "Hw2ul1L7Vg5c"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean squared error function\n",
        "def MSE(O, T):  # O = self.predict()\n",
        "  # Problem 1.(b): fill here\n",
        "  result = 0\n",
        "  size = np.size(O)\n",
        "  result = (1/size) * (O-T) ** 2\n",
        "  return np.sum(result)\n",
        "\n",
        "# Derivative of hyperbolic tangent function\n",
        "def dMSE(O, T):\n",
        "  # Problem 1.(b): fill here\n",
        "  result = O-T\n",
        "  return result"
      ],
      "metadata": {
        "id": "g0MG-Fl4IMd_"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "\n",
        "  def __init__(self, learning_rate=0.035, n_epochs=100000, n_inputs=2, n_hiddens=2, n_outputs=1):\n",
        "    self.lr = learning_rate\n",
        "    self.n_epochs = n_epochs\n",
        "    \n",
        "    self.n_inputs = n_inputs\n",
        "    self.n_hiddens = n_hiddens\n",
        "    self.n_outputs = n_outputs\n",
        "\n",
        "    self.first_layer_activation_func = tanh\n",
        "    self.first_layer_dactivation_func = dtanh\n",
        "    self.second_layer_activation_func = sigmoid\n",
        "    self.second_layer_dactivation_func = dsigmoid\n",
        "    self.loss_func = MSE\n",
        "    self.dloss_func = dMSE\n",
        "    self.first_layer_weights = None\n",
        "    self.first_layer_bias = None\n",
        "    self.second_layer_weights = None\n",
        "    self.second_layer_bias = None\n",
        "  \n",
        "\n",
        "  def _init_params(self):\n",
        "    # Problem 1.(c): fill here\n",
        "  \n",
        "    self.first_layer_weights = np.reshape(np.random.random(4), (2, 2))  # 2x2 random matrix\n",
        "    self.first_layer_bias = np.array([[0.0, 0.0]])\n",
        "    #self.first_layer_bias = np.reshape(np.random.random(2), (1, 2))\n",
        "    \n",
        "    self.second_layer_weights = np.reshape(np.random.random(2), (2, 1))\n",
        "    self.second_layer_bias = np.array([[0.]])\n",
        "\n",
        "\n",
        "  def _forward(self, X, T):\n",
        "    # Problem 1.(d): fill here\n",
        "    X = np.atleast_2d(X)\n",
        "    T = np.atleast_2d(T)\n",
        "\n",
        "    Z1 = np.dot(X, self.first_layer_weights) + self.first_layer_bias  # != np.dot(weight, X)\n",
        "    A1 = self.first_layer_activation_func(Z1)\n",
        "    Z2 = np.dot(A1, self.second_layer_weights) + self.second_layer_bias\n",
        "    A2 = self.second_layer_activation_func(Z2)\n",
        "    loss = self.loss_func(A2, T)\n",
        "    return Z1, A1, Z2, A2, loss\n",
        "\n",
        "\n",
        "  def _backward(self, X, Z1, A1, Z2, A2, T):\n",
        "    # Problem 1.(e): fill here\n",
        "    X = np.atleast_2d(X)\n",
        "    T = np.atleast_2d(T)\n",
        "\n",
        "    error2 = self.dloss_func(A2, T) * self.second_layer_dactivation_func(Z2) # 1x1 matrix\n",
        "    dW2 = np.dot(np.transpose(A1), error2)  # np.atleast_2d(A1)  # 2x1 matrix\n",
        "\n",
        "    error1 = np.zeros(np.shape(Z1))  # 1x2 matrix\n",
        "    for id, sp in enumerate(self.second_layer_weights):\n",
        "      for i in range(np.size(sp)):\n",
        "        error1[0][id] += sp[i] * error2[0][i]  # error2[i] (X)\n",
        "    error1 = error1 * self.first_layer_dactivation_func(Z1)\n",
        "    dW1 = np.dot(np.transpose(X), error1)  # 2x2 matrix\n",
        "   \n",
        "    dB2 = error2\n",
        "    dB1 = error1\n",
        "\n",
        "    return dW1, dB1, dW2, dB2\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "     #return self._forward(X, None)\n",
        "     Z1 = np.dot(X, self.first_layer_weights) + self.first_layer_bias  # np.dot(weight, X) != np.dot(X, weight)\n",
        "     A1 = self.first_layer_activation_func(Z1)\n",
        "     Z2 = np.dot(A1, self.second_layer_weights) + self.second_layer_bias\n",
        "     A2 = self.second_layer_activation_func(Z2)\n",
        "     return A2\n",
        "\n",
        "\n",
        "  def fit(self, X, T):\n",
        "    \n",
        "    self._init_params()\n",
        "    loss_trace = []\n",
        "\n",
        "    for _ in range(self.n_epochs):\n",
        "      for idx, sample in enumerate(X):\n",
        "        Z1, A1, Z2, A2, loss = self._forward(sample, T[0][idx])\n",
        "        dW1, dB1, dW2, dB2 = self._backward(sample, Z1, A1, Z2, A2, T[0][idx])\n",
        "        \n",
        "        # Problem 1.(f): fill here\n",
        "        self.first_layer_weights -= self.lr * dW1\n",
        "        self.second_layer_weights -= self.lr * dW2\n",
        "        self.first_layer_bias -= self.lr * dB1\n",
        "        self.second_layer_bias -= self.lr * dB2\n",
        "        \n",
        "      loss_trace.append(loss)\n",
        "\n",
        "    return loss_trace"
      ],
      "metadata": {
        "id": "g8VxeUNJWUQi"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1.(g): fill here\n",
        "mlp = MLP()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "T = np.array([[0, 1, 1, 0]])\n",
        "\n",
        "loss_trace = mlp.fit(X, T)\n",
        "y = mlp.predict(X)\n",
        "\n"
      ],
      "metadata": {
        "id": "LrrU89LYg9Ch"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_trace)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "HHn035KyleRt",
        "outputId": "d56b8fc5-6d36-476f-833e-b7dcf0164370"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out XOR outputs for an input matrix X\n",
        "print(mlp.predict(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vzx3NJTlodj",
        "outputId": "5b134b5f-df51-4fae-b319-0d5786819257"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.01240683]\n",
            " [0.99070411]\n",
            " [0.9907089 ]\n",
            " [0.01288546]]\n"
          ]
        }
      ]
    }
  ]
}